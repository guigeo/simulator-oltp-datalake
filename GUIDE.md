# üìò Guia Completo - Simulador OLTP Hospitalar CDC

> **Tudo que voc√™ precisa saber para usar este projeto em um √∫nico arquivo.**

---

## üìñ √çndice

1. [O Que √â](#o-que-√©)
2. [Estrutura](#estrutura)
3. [Pr√©-requisitos](#pr√©-requisitos)
4. [Instala√ß√£o & Configura√ß√£o](#instala√ß√£o--configura√ß√£o)
5. [Passo-a-Passo de Execu√ß√£o](#passo-a-passo-de-execu√ß√£o)
6. [Comandos Dispon√≠veis](#comandos-dispon√≠veis)
7. [Gera√ß√£o de Dados](#gera√ß√£o-de-dados)
8. [Observabilidade & Logs](#observabilidade--logs)
9. [Troubleshooting](#troubleshooting)
10. [Refer√™ncia T√©cnica](#refer√™ncia-t√©cnica)

---

## O Que √â?

**Simulador OLTP Hospitalar** √© uma automa√ß√£o em Python que simula inser√ß√µes cont√≠nuas em um banco PostgreSQL com estrutura hospitalar realista, ideal para testes de **CDC (Change Data Capture)** via Debezium.

### Caracter√≠sticas Principais
- ‚úÖ **Inser√ß√£o cont√≠nua** com intervalo configur√°vel e jitter aleat√≥rio
- ‚úÖ **7 tabelas OLTP** com 13.000+ registros iniciais
- ‚úÖ **Gera√ß√£o de dados** com Faker (locale pt_BR)
- ‚úÖ **CLI Typer** com 5 comandos prontos
- ‚úÖ **Resiliente** com reconex√£o autom√°tica
- ‚úÖ **Observ√°vel** com logs estruturados
- ‚úÖ **CDC-ready** para Debezium

---

## Estrutura

```
alimentador_bd/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ .env                    ‚Üê Seu arquivo de credenciais
‚îÇ   ‚îú‚îÄ‚îÄ .env.example            ‚Üê Template
‚îÇ   ‚îî‚îÄ‚îÄ settings.toml           ‚Üê Configura√ß√µes
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îú‚îÄ‚îÄ 01_schema.sql           ‚Üê Schema (7 tabelas)
‚îÇ   ‚îú‚îÄ‚îÄ 02_indexes.sql          ‚Üê √çndices (9)
‚îÇ   ‚îú‚îÄ‚îÄ 03_seed-lookups.sql     ‚Üê Dados iniciais
‚îÇ   ‚îî‚îÄ‚îÄ 99_drop_all.sql         ‚Üê Limpeza
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ cli.py                  ‚Üê CLI Typer (5 comandos)
‚îÇ   ‚îú‚îÄ‚îÄ db_init.py              ‚Üê Conex√£o + init
‚îÇ   ‚îú‚îÄ‚îÄ seed.py                 ‚Üê Seed functions
‚îÇ   ‚îú‚îÄ‚îÄ stream.py               ‚Üê Streaming cont√≠nuo
‚îÇ   ‚îú‚îÄ‚îÄ reset.py                ‚Üê Reset total
‚îÇ   ‚îú‚îÄ‚îÄ data_gen.py             ‚Üê Faker generators
‚îÇ   ‚îú‚îÄ‚îÄ validators.py           ‚Üê Valida√ß√£o + cache LRU
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ logs/                       ‚Üê Gerado em runtime
‚îú‚îÄ‚îÄ test_connection.py          ‚Üê Teste de conex√£o
‚îú‚îÄ‚îÄ requirements.txt            ‚Üê Depend√™ncias
‚îú‚îÄ‚îÄ Makefile                    ‚Üê Atalhos
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ AGENTS.md                   ‚Üê Especifica√ß√£o (refer√™ncia)
‚îî‚îÄ‚îÄ GUIDE.md                    ‚Üê Este arquivo
```

---

## Pr√©-requisitos

### Essencial
- **Python 3.11+** instalado
- **PostgreSQL 14+** rodando em `10.42.88.67:5441`
- **Credenciais**: usu√°rio `app` / senha `app123` / banco `postgres`

### Verificar Pr√©-requisitos
```bash
# Python
python --version

# PostgreSQL (se remoto)
telnet 10.42.88.67 5441  # Ctrl+] then quit (ou Ctrl+C)
```

---

## Instala√ß√£o & Configura√ß√£o

### 1Ô∏è‚É£ Clonar/Acessar o Projeto
```bash
cd /home/henrique.ferreira/workspace/alimentador_bd
```

### 2Ô∏è‚É£ Copiar Arquivo de Ambiente
```bash
cp config/.env.example config/.env
```

**Verificar que `.env` cont√©m:**
```env
PG_HOST=10.42.88.67
PG_PORT=5441
PG_USER=app
PG_PASSWORD=app123
PG_DATABASE=postgres
```

### 3Ô∏è‚É£ Testar Conex√£o
```bash
# Instalar depend√™ncias m√≠nimas
pip install python-dotenv psycopg2-binary

# Executar teste
python test_connection.py
```

**Sa√≠da esperada:**
```
‚úÖ Conex√£o estabelecida com sucesso!
‚úÖ Query executada: SELECT 1
‚úÖ PostgreSQL Info: PostgreSQL 14.x...
‚ú® TUDO OK! Pronto para usar.
```

### 4Ô∏è‚É£ Instalar Depend√™ncias Completas
```bash
make install

# Ou manualmente:
# python -m venv .venv
# source .venv/bin/activate  (Windows: .venv\Scripts\activate)
# pip install -r requirements.txt
```

**Depend√™ncias instaladas:**
- psycopg2-binary (driver PostgreSQL)
- python-dotenv (arquivo .env)
- typer (CLI)
- faker (gera√ß√£o de dados)
- pydantic (valida√ß√£o)

---

## Passo-a-Passo de Execu√ß√£o

### üìç Passo 1: Inicializar Banco de Dados

Cria o schema, √≠ndices e dados de lookup iniciais.

```bash
make init
```

**O que acontece:**
- ‚úì Cria 7 tabelas (pacientes, medicos, convenios, etc.)
- ‚úì Cria 7 triggers para `updated_at`
- ‚úì Cria 9 √≠ndices estrat√©gicos
- ‚úì Carrega 2 conv√™nios iniciais (SUS, SaudePlus)

**Tempo:** ~3-5 segundos

---

### üìç Passo 2: Popular com Dados Iniciais

Popula ~13.000 registros nas 7 tabelas usando Faker pt_BR.

```bash
make seed
```

**O que acontece:**
```
M√©dicos: +50 (total=200)
Pacientes: +50 (total=2000)
Convenios: +12 (total=12)
Pacientes_Conv√™nios: +50 (total=2500)
Consultas: +50 (total=4000)
Exames: +50 (total=3500)
Interna√ß√µes: +50 (total=1200)
```

**Tempo:** ~2-5 minutos (depende da rede)

**Volumes Finais:**
| Tabela | Registros |
|--------|-----------|
| pacientes | 2.000 |
| medicos | 200 |
| convenios | 12 |
| pacientes_convenios | ~2.500 |
| consultas | 4.000 |
| exames | 3.500 |
| internacoes | 1.200 |
| **TOTAL** | **~13.000** |

---

### üìç Passo 3: Iniciar Streaming Cont√≠nuo

Inicia inser√ß√£o cont√≠nua de eventos (consultas, exames, interna√ß√µes, novos pacientes).

```bash
make stream
```

**O que acontece:**
- ‚úì Insere eventos continuamente (intervalo 2s + jitter)
- ‚úì Mix realista: 55% consulta, 25% exame, 15% interna√ß√£o, 10% paciente
- ‚úì Valida√ß√£o de FKs com cache LRU
- ‚úì Transa√ß√µes seguras com commit/rollback
- ‚úì Logs em console + arquivo

**Sa√≠da esperada:**
```
INFO ... Iniciando stream com intervalo 2s e jitter at√© 400ms
DEBUG ... Novo paciente inserido.
DEBUG ... Consulta inserida: 1234
INFO ... Stream ciclo 50: consultas: 27 | exames: 12 | internacoes: 7 | pacientes: 4
```

**Parar o stream:**
```
Ctrl+C
```

---

### üìç Passo 4 (Opcional): Monitorar em Tempo Real

Em **outro terminal**, execute:

```bash
# Ver contagens atualizadas a cada 5s
watch -n 5 'python -m scripts.cli counts'

# Ou manualmente:
python -m scripts.cli counts
```

**Sa√≠da esperada:**
```
=== Contagem de Registros ===
pacientes..................... 2,000
medicos......................    200
convenios.....................     12
pacientes_convenios........  2,500
consultas.................  4,100  (crescendo!)
exames....................  3,600  (crescendo!)
internacoes...............  1,250  (crescendo!)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL....................  13,162+
```

---

### üìç Passo 5 (Opcional): Reset Total

**‚ö†Ô∏è CUIDADO: Deleta todos os dados!**

```bash
make reset
```

Confirmar√° antes de executar. Depois recria schema e popula novamente.

---

## Comandos Dispon√≠veis

### Via Makefile (Recomendado)

```bash
make init              # Criar schema + √≠ndices + lookups
make seed              # Popular dados iniciais (~13.000)
make stream            # Inser√ß√£o cont√≠nua
make reset             # Drop + recreate + seed
make counts            # Ver contagens
make fmt               # Formatar c√≥digo (ruff + black)
make lint              # Verificar c√≥digo (ruff)
make clean             # Remover venv + __pycache__
make help              # Ver ajuda
```

### Via Python (Direto)

```bash
# Ativar venv primeiro
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Comandos
python -m scripts.cli init-db-cmd
python -m scripts.cli seed [--volume 2]
python -m scripts.cli stream [--interval 2] [--batch-size 50]
python -m scripts.cli reset
python -m scripts.cli counts

# Teste de conex√£o
python test_connection.py
```

---

## Gera√ß√£o de Dados

### Faker pt_BR

Usa **Faker com locale pt_BR** para gerar dados realistas em portugu√™s:

```python
# Exemplos
CPF:      123.456.789-00 (com valida√ß√£o de d√≠gitos)
CRM:      123456SP (6 d√≠gitos + 2 letras UF)
CNPJ:     12.345.678/0001-99 (com valida√ß√£o)
Nomes:    Jo√£o da Silva, Maria Santos (portugu√™s)
Telefone: (11) 98765-4321
Endere√ßo: Rua das Flores, 123 - S√£o Paulo, SP
```

### Volumes Padr√£o

Configur√°veis em `config/.env`:

```env
SEED_PACIENTES=2000
SEED_MEDICOS=200
SEED_CONVENIOS=12
SEED_CONSULTAS=4000
SEED_EXAMES=3500
SEED_INTERNACOES=1200
SEED_PACIENTES_CONVENIOS=2500
```

### Status e Tipos

**Status de Consulta** (distribui√ß√£o ponderada):
- 55% = `agendada`
- 35% = `realizada`
- 5% = `cancelada`
- 5% = `faltou`

**Tipos de Exame:**
- Hemograma, Raio-X, Tomografia, Ultrassom, PCR, ECG, etc.

**Interna√ß√µes:**
- 70% com `data_saida` (alta hospitalar)
- 30% sem `data_saida` (ainda internado)

---

## Observabilidade & Logs

### Arquivos de Log

Gerados em `/logs`:
```
app.log        ‚Üí Log geral (init, seed, CLI)
stream.log     ‚Üí Log espec√≠fico do stream
errors.log     ‚Üí Apenas erros
```

### Ver Logs em Tempo Real

```bash
# Log geral
tail -f logs/app.log

# Apenas erros
grep "ERROR" logs/app.log
tail -f logs/app.log | grep "ERROR\|WARNING"

# Todos os logs
ls -la logs/
```

### Formato de Log

```
2025-11-05 14:23:45,123 INFO oltp.simulator [seed_medicos] - M√©dicos: +50 (total=200)
```

### Contadores por Ciclo

A cada 50 ciclos do stream, exibe:
```
INFO ... Stream ciclo 50: consultas: 27 | exames: 12 | internacoes: 7 | pacientes: 4
```

---

## Troubleshooting

### ‚ùå Erro: "Conex√£o recusada"

**Problema:** `psycopg2.OperationalError: could not connect to server`

**Verificar:**
```bash
# Testar IP/porta
ping 10.42.88.67
telnet 10.42.88.67 5441

# Ou via Python
python test_connection.py

# Manualmente com psql
psql -h 10.42.88.67 -p 5441 -U app -d postgres -c "SELECT 1"
```

---

### ‚ùå Erro: "Database n√£o existe"

**Problema:** `database "postgres" does not exist`

**Solu√ß√£o:**
```bash
# Criar banco (se for necess√°rio)
createdb -U app -h 10.42.88.67 -p 5441 postgres

# Ou mudar em config/.env para outro banco existente
PG_DATABASE=seu_banco_existente
```

---

### ‚ùå Erro: "M√≥dulo n√£o encontrado"

**Problema:** `ModuleNotFoundError: No module named 'typer'`

**Solu√ß√£o:**
```bash
# Reinstalar depend√™ncias
pip install -r requirements.txt

# Ou via venv
source .venv/bin/activate
pip install -r requirements.txt
```

---

### ‚ùå Aviso: "CPF duplicado"

**Problema:** Alguns registros n√£o s√£o inseridos durante seed

**Causa:** Com Faker, volumes altos podem gerar duplicatas

**√â normal!** O sistema ignora automaticamente.

**Ver logs:**
```bash
grep "CPF duplicado\|IntegrityError" logs/*.log
```

---

### ‚ùå Stream para ap√≥s alguns eventos

**Problema:** Inser√ß√£o funciona poucos segundos depois para

**Verificar:**
1. Logs: `tail -f logs/app.log`
2. Conex√£o: `python test_connection.py`
3. Dados: `python -m scripts.cli counts`
4. Reseedie se vazio: `make seed`

---

### ‚ùå Stream muito lento

**Problema:** Inserindo 1-2 registros/segundo

**Solu√ß√µes:**
```bash
# 1. Reduzir intervalo
STREAM_INTERVAL_SECONDS=0.5

# 2. Aumentar batch
BATCH_SIZE=100

# 3. Otimizar √≠ndices
psql -h 10.42.88.67 -p 5441 -U app -d postgres -f sql/02_indexes.sql
```

---

## Refer√™ncia T√©cnica

### Schema OLTP (7 Tabelas)

#### pacientes
```sql
id (BIGSERIAL PK) | nome | nascimento | cpf (UK) | telefone 
endereco | data_cadastro | created_at | updated_at
```

#### medicos
```sql
id (BIGSERIAL PK) | nome | crm (UK) | especialidade | telefone 
created_at | updated_at
```

#### convenios
```sql
id (BIGSERIAL PK) | nome | cnpj (UK) | tipo | cobertura 
created_at | updated_at
```

#### pacientes_convenios (N:N)
```sql
id (BIGSERIAL PK) | paciente_id (FK) | convenio_id (FK) 
numero_carteira | validade | created_at | updated_at
(UK: paciente_id, convenio_id)
```

#### consultas
```sql
id (BIGSERIAL PK) | paciente_id (FK) | medico_id (FK) | data 
motivo | status (CHECK) | created_at | updated_at
```

#### exames
```sql
id (BIGSERIAL PK) | paciente_id (FK) | tipo_exame | data 
resultado | created_at | updated_at
```

#### internacoes
```sql
id (BIGSERIAL PK) | paciente_id (FK) | data_entrada | data_saida 
motivo | quarto | created_at | updated_at
(CHECK: data_saida >= data_entrada)
```

### Constraints

- **PK:** BIGSERIAL em todas as tabelas
- **UK:** CPF, CRM, CNPJ (√∫nicos)
- **FK:** ON UPDATE CASCADE, ON DELETE RESTRICT
- **Triggers:** updated_at autom√°tico em UPDATE

### √çndices (9)

```sql
idx_pacientes_cpf
idx_medicos_crm
idx_consultas_paciente
idx_consultas_medico
idx_consultas_data
idx_exames_paciente
idx_exames_data
idx_internacoes_paciente
idx_internacoes_datas
```

---

### Depend√™ncias Python

```
psycopg2-binary==2.9.9      (driver PostgreSQL)
python-dotenv==1.0.0        (arquivo .env)
typer==0.12.3               (CLI)
faker==21.0.0               (gera√ß√£o de dados)
pydantic==2.5.0             (valida√ß√£o)
```

---

### Volumes e Performance

| Opera√ß√£o | Tempo | Volume |
|----------|-------|--------|
| Init DB | 3-5s | Schema + triggers + √≠ndices |
| Seed | 2-5m | ~13.000 registros |
| Stream (1 evento) | 100-500ms | 1 INSERT em transa√ß√£o |
| Stream (1 min) | 1m | ~30-50 eventos |
| Stream (1 hora) | 1h | ~2.000-3.000 eventos |
| Stream (1 dia) | 1d | ~50.000+ eventos |

---

### Configura√ß√µes (config/.env)

```env
# Conex√£o
PG_HOST=10.42.88.67
PG_PORT=5441
PG_USER=app
PG_PASSWORD=app123
PG_DATABASE=postgres

# Stream
STREAM_INTERVAL_SECONDS=2        (intervalo em segundos)
BATCH_SIZE=50                     (registros por batch)
MAX_JITTER_MS=400                 (varia√ß√£o aleat√≥ria em ms)

# Seed
SEED_PACIENTES=2000
SEED_MEDICOS=200
SEED_CONVENIOS=12
SEED_CONSULTAS=4000
SEED_EXAMES=3500
SEED_INTERNACOES=1200
SEED_PACIENTES_CONVENIOS=2500

# Logs
LOG_LEVEL=INFO
```

---

### Eventos do Stream (Distribui√ß√£o)

```
10% = Novo paciente
55% = Nova consulta
25% = Novo exame
15% = Nova interna√ß√£o
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
100% = Total por ciclo
```

### Cache LRU (Validators)

```
check_paciente_exists()   ‚Üí 512 entradas
check_medico_exists()     ‚Üí 512 entradas
check_convenio_exists()   ‚Üí 512 entradas
```

Invalida automaticamente ap√≥s cada INSERT de novo paciente/m√©dico/conv√™nio.

---

## Pr√≥ximos Passos

### Para CDC/Debezium

1. ‚úÖ Dados populados? Verifique com `make counts`
2. ‚úÖ Stream rodando? Observe em `tail -f logs/app.log`
3. ‚û°Ô∏è **Habilite WAL logging** no PostgreSQL
4. ‚û°Ô∏è **Configure Debezium** para capturar eventos
5. ‚û°Ô∏è **Envie para Kafka/Pulsar** ou destino

### Valida√ß√µes Sugeridas

- Todos os eventos foram capturados?
- Consist√™ncia de dados (origem vs destino)?
- Performance de CDC?
- Failover e recovery?

---

## Refer√™ncias R√°pidas

### Comandos √öteis

```bash
# Testar conex√£o
python test_connection.py

# Ver contagens
python -m scripts.cli counts

# Limpar venv
make clean

# Formatar c√≥digo
make fmt

# Ver ajuda
make help
```

### Arquivos Importantes

| Arquivo | Prop√≥sito |
|---------|-----------|
| `config/.env` | Suas credenciais (N√ÉO commitar!) |
| `config/.env.example` | Template seguro (OK commitar) |
| `sql/01_schema.sql` | Schema principal |
| `scripts/cli.py` | CLI Typer |
| `scripts/stream.py` | Inser√ß√£o cont√≠nua |
| `scripts/data_gen.py` | Geradores Faker |
| `requirements.txt` | Depend√™ncias |
| `Makefile` | Atalhos de comando |

---

## FAQ

### P: Posso pausar e retomar o stream?
**R:** Sim! Use `Ctrl+C` para parar. Execute `make stream` novamente para retomar.

### P: Como aumentar o volume?
**R:** Edite `config/.env` e altere os valores `SEED_*`. Depois execute `make seed` novamente.

### P: Stream est√° lento?
**R:** Reduza `STREAM_INTERVAL_SECONDS` ou aumente `BATCH_SIZE` em `config/.env`.

### P: Como resetar tudo?
**R:** Execute `make reset` (cuidado - deleta dados!).

### P: Que vers√£o de PostgreSQL √© necess√°ria?
**R:** PostgreSQL 14+, idealmente com WAL logging habilitado para CDC.

### P: Posso usar localmente?
**R:** Sim! Mude `config/.env` para:
```env
PG_HOST=localhost
PG_PORT=5432
PG_USER=postgres
PG_PASSWORD=postgres
```

---

## Suporte & Contato

- **C√≥digo:** Todos os 29 arquivos prontos para usar
- **Documenta√ß√£o:** Este guia + AGENTS.md (especifica√ß√£o)
- **Logs:** Verifique `/logs` para diagn√≥stico
- **Teste:** Use `python test_connection.py` para validar

---

## Licen√ßa

C√≥digo livre para uso em testes de CDC/Debezium.

---

**√öltima atualiza√ß√£o:** 5 de novembro de 2025

‚ú® **Bom desenvolvimento!** üöÄ
